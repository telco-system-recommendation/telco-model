{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90333a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\Documents\\ASAH 2025\\CAPSTONE\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (6.4.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (3.10.7)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from catboost) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from plotly->catboost) (2.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\Documents\\ASAH 2025\\CAPSTONE\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install xgboost\n",
    "!pip install catboost lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# MASTER IMPORT FOR TELCO MACHINE LEARNING PROJECT\n",
    "# =========================================================\n",
    "\n",
    "# Core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization (EDA)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Saving / Loading\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "# SCIKIT-LEARN PREPROCESSING\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder,\n",
    "    label_binarize\n",
    ")\n",
    "\n",
    "# SCIKIT-LEARN MODEL SELECTION\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "\n",
    "# SCIKIT-LEARN METRICS\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# MACHINE LEARNING MODELS\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fd492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>avg_data_usage_gb</th>\n",
       "      <th>pct_video_usage</th>\n",
       "      <th>avg_call_duration</th>\n",
       "      <th>sms_freq</th>\n",
       "      <th>monthly_spend</th>\n",
       "      <th>topup_freq</th>\n",
       "      <th>travel_score</th>\n",
       "      <th>complaint_count</th>\n",
       "      <th>target_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00001</td>\n",
       "      <td>Prepaid</td>\n",
       "      <td>Realme</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.804146</td>\n",
       "      <td>7.98</td>\n",
       "      <td>13</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.284419</td>\n",
       "      <td>0</td>\n",
       "      <td>General Offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00002</td>\n",
       "      <td>Postpaid</td>\n",
       "      <td>Vivo</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115086</td>\n",
       "      <td>0</td>\n",
       "      <td>General Offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00003</td>\n",
       "      <td>Postpaid</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>4.61</td>\n",
       "      <td>13</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402998</td>\n",
       "      <td>0</td>\n",
       "      <td>General Offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00004</td>\n",
       "      <td>Prepaid</td>\n",
       "      <td>Apple</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.420158</td>\n",
       "      <td>6.96</td>\n",
       "      <td>8</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.302169</td>\n",
       "      <td>0</td>\n",
       "      <td>General Offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00005</td>\n",
       "      <td>Prepaid</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.251638</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.487911</td>\n",
       "      <td>0</td>\n",
       "      <td>General Offer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id plan_type device_brand  avg_data_usage_gb  pct_video_usage  \\\n",
       "0      C00001   Prepaid       Realme               1.50         0.804146   \n",
       "1      C00002  Postpaid         Vivo               1.09         0.107686   \n",
       "2      C00003  Postpaid       Xiaomi               3.24         0.313894   \n",
       "3      C00004   Prepaid        Apple               5.32         0.420158   \n",
       "4      C00005   Prepaid       Huawei               1.91         0.251638   \n",
       "\n",
       "   avg_call_duration  sms_freq  monthly_spend  topup_freq  travel_score  \\\n",
       "0               7.98        13        70000.0           4      0.284419   \n",
       "1               9.56         9        63000.0           3      0.115086   \n",
       "2               4.61        13        89000.0           7      0.402998   \n",
       "3               6.96         8        67000.0           4      0.302169   \n",
       "4              11.01        21        72000.0           5      0.487911   \n",
       "\n",
       "   complaint_count   target_offer  \n",
       "0                0  General Offer  \n",
       "1                0  General Offer  \n",
       "2                0  General Offer  \n",
       "3                0  General Offer  \n",
       "4                0  General Offer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw/data_capstone.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001d7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 42,669\n",
      "Testing samples: 1,954\n",
      "Features: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load training data (sudah balanced dengan SMOTE)\n",
    "X_train = np.load('data/processed/X_train.npy')\n",
    "y_train = np.load('data/processed/y_train.npy')\n",
    "\n",
    "# Load testing data (original)\n",
    "X_test = np.load('data/processed/X_test.npy')\n",
    "y_test = np.load('data/processed/y_test.npy')\n",
    "\n",
    "# Load artifacts\n",
    "with open('data/processed/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('data/processed/label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open('data/processed/feature_names.pkl', 'rb') as f:\n",
    "    feature_names = pickle.load(f)\n",
    "\n",
    "print(f\"Training samples: {len(y_train):,}\")\n",
    "print(f\"Testing samples: {len(y_test):,}\")\n",
    "print(f\"Features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bcc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_features = [\n",
    "    'avg_data_usage_gb',\n",
    "    'pct_video_usage',\n",
    "    'avg_call_duration',\n",
    "    'sms_freq',\n",
    "    'monthly_spend',\n",
    "    'topup_freq',\n",
    "    'travel_score',\n",
    "    'complaint_count'\n",
    "]\n",
    "\n",
    "X = df[behavior_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0e468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5edb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_id', 'plan_type', 'device_brand', 'avg_data_usage_gb', 'pct_video_usage', 'avg_call_duration', 'sms_freq', 'monthly_spend', 'topup_freq', 'travel_score', 'complaint_count', 'target_offer']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24bc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_offer_cosine(customer_index, top_k=6):\n",
    "    \n",
    "    # Hitung cosine similarity antara satu customer vs semua\n",
    "    sim_scores = cosine_similarity(\n",
    "        X_scaled[customer_index].reshape(1, -1),\n",
    "        X_scaled\n",
    "    )[0]\n",
    "\n",
    "    # Urutkan customer paling mirip (descending), skip diri sendiri\n",
    "    similar_indices = sim_scores.argsort()[::-1][1 : top_k+1]\n",
    "\n",
    "    # Ambil offer dari pelanggan mirip\n",
    "    similar_offers = df.loc[similar_indices, \"target_offer\"]\n",
    "\n",
    "    # Hitung distribusi offer\n",
    "    freq = similar_offers.value_counts()\n",
    "\n",
    "    # Ambil rekomendasi (offer paling sering)\n",
    "    recommended = freq.idxmax()\n",
    "\n",
    "    return recommended, freq, similar_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3fd0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Recommended Offer: Retention Offer\n",
      "\n",
      "üìä Similar Customer Offer Distribution:\n",
      " target_offer\n",
      "Retention Offer         3\n",
      "General Offer           2\n",
      "Device Upgrade Offer    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üßç Similar Customer Index: [1949 9789 4426 2916 1392 5225 8535]\n"
     ]
    }
   ],
   "source": [
    "rec, freq, idx = recommend_offer_cosine(1500, top_k=7)\n",
    "\n",
    "print(\"üéØ Recommended Offer:\", rec)\n",
    "print(\"\\nüìä Similar Customer Offer Distribution:\\n\", freq)\n",
    "print(\"\\nüßç Similar Customer Index:\", idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378efe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(k=7, sample=300):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for i in np.random.choice(len(df), sample, replace=False):\n",
    "        rec, _, _ = recommend_offer_cosine(i, top_k=k)\n",
    "\n",
    "        true_offer = df.iloc[i]['target_offer']\n",
    "\n",
    "        if rec == true_offer:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c98c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@7: 0.728\n"
     ]
    }
   ],
   "source": [
    "accuracy = precision_at_k(k=7, sample=500)\n",
    "print(\"Precision@7:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606a6737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Data Booster' 'Device Upgrade Offer' 'Family Plan Offer' 'General Offer'\n",
      " 'Retention Offer' 'Roaming Pass' 'Streaming Partner Pack' 'Top-up Promo'\n",
      " 'Voice Bundle']\n",
      "Target mapping: {'Data Booster': 0, 'Device Upgrade Offer': 1, 'Family Plan Offer': 2, 'General Offer': 3, 'Retention Offer': 4, 'Roaming Pass': 5, 'Streaming Partner Pack': 6, 'Top-up Promo': 7, 'Voice Bundle': 8}\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/raw/data_capstone.csv')\n",
    "\n",
    "# 1.a Feature engineering - add cost_per_gb and engagement_score (simple proxy)\n",
    "df['cost_per_gb'] = df['monthly_spend'] / df['avg_data_usage_gb']\n",
    "df['cost_per_gb'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df['cost_per_gb'].fillna(df['cost_per_gb'].median(), inplace=True)\n",
    "\n",
    "# engagement_score: normalized combination of usage, pct_video_usage, topup_freq\n",
    "df['engagement_score'] = (\n",
    "    (df['avg_data_usage_gb'].rank(pct=True) * 0.5) +\n",
    "    (df['pct_video_usage'].rank(pct=True) * 0.3) +\n",
    "    (df['topup_freq'].rank(pct=True) * 0.2)\n",
    ")\n",
    "\n",
    "# 1.b Features to use (numerical + optionally encoded categorical)\n",
    "features = [\n",
    "    'avg_data_usage_gb', 'pct_video_usage', 'avg_call_duration', 'sms_freq',\n",
    "    'monthly_spend', 'topup_freq', 'travel_score', 'complaint_count',\n",
    "    'cost_per_gb', 'engagement_score'\n",
    "]\n",
    "\n",
    "# Keep some categorical for CatBoost handling later\n",
    "cat_features = ['plan_type', 'device_brand']\n",
    "\n",
    "# 1.c Target encode (use the mapping you provided if you want numeric labels)\n",
    "le = LabelEncoder()\n",
    "df['target_label'] = le.fit_transform(df['target_offer'])  # stores encoded classes 0..8\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n",
    "# store mapping dict if needed\n",
    "target_mapping = {cls: int(lbl) for lbl, cls in enumerate(le.classes_)}\n",
    "print(\"Target mapping:\", target_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5dce0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (train): {0: np.float64(1.3938669852648347), 1: np.float64(0.7400359446030236), 2: np.float64(13.645224171539962), 3: np.float64(0.18304960644334614), 4: np.float64(1.4592453616843861), 5: np.float64(11.965811965811966), 6: np.float64(4.320987654320987), 7: np.float64(3.003003003003003), 8: np.float64(16.203703703703702)}\n"
     ]
    }
   ],
   "source": [
    "# 2) Split - stratify by target to preserve distribution\n",
    "X = df[features + cat_features]  # note: cat_features included (for CatBoost we will pass indices)\n",
    "y = df['target_label'].values\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# 2.a Scaling numeric features for models that need it (XGBoost/LGB prefer scaled numeric but not required)\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[features])\n",
    "X_val_num = scaler.transform(X_val[features])\n",
    "X_test_num = scaler.transform(X_test[features])\n",
    "\n",
    "# Create dataframe-like structures for model input\n",
    "X_train_model = pd.DataFrame(X_train_num, columns=features, index=X_train.index)\n",
    "X_val_model = pd.DataFrame(X_val_num, columns=features, index=X_val.index)\n",
    "X_test_model = pd.DataFrame(X_test_num, columns=features, index=X_test.index)\n",
    "\n",
    "# attach categorical columns back (as raw strings) for CatBoost\n",
    "X_train_model[cat_features] = X_train[cat_features].reset_index(drop=True)\n",
    "X_val_model[cat_features]   = X_val[cat_features].reset_index(drop=True)\n",
    "X_test_model[cat_features]  = X_test[cat_features].reset_index(drop=True)\n",
    "\n",
    "# 2.b Sample weights to handle imbalance (inverse freq)\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = {i: (len(y_train) / (len(class_counts) * count)) for i, count in enumerate(class_counts)}\n",
    "sample_weight_train = np.array([class_weights[int(lbl)] for lbl in y_train])\n",
    "print(\"Class weights (train):\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38f04a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Evaluation helper\n",
    "def evaluate_model(clf, X_test_input, y_test, model_name=\"model\", proba=True, catboost=False):\n",
    "    \"\"\"\n",
    "    clf: trained classifier (fitted)\n",
    "    X_test_input: dataframe with numeric + categorical as needed\n",
    "    y_test: true labels\n",
    "    \"\"\"\n",
    "    # If classifier expects numpy numeric only (XGBoost/LGB), provide numeric features only\n",
    "    if model_name in (\"xgboost\", \"lightgbm\"):\n",
    "        X_eval = X_test_input[features].values\n",
    "    else:\n",
    "        X_eval = X_test_input  # CatBoost can take dataframe with cat columns\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = clf.predict(X_eval)\n",
    "    # Probabilities (for ROC-AUC)\n",
    "    try:\n",
    "        y_proba = clf.predict_proba(X_eval)\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "    \n",
    "    f1_w = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"==== Evaluation {model_name} ====\")\n",
    "    print(\"F1-weighted: {:.4f}\".format(f1_w))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix shape:\", cm.shape)\n",
    "    \n",
    "    # ROC-AUC (multiclass) if probabilities available\n",
    "    if y_proba is not None:\n",
    "        y_test_binarized = label_binarize(y_test, classes=np.arange(len(le.classes_)))\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "            print(\"ROC-AUC (ovr):\", auc)\n",
    "        except Exception as e:\n",
    "            print(\"ROC-AUC error:\", e)\n",
    "    \n",
    "    return {\"f1_weighted\": f1_w, \"confusion_matrix\": cm, \"y_pred\": y_pred, \"y_proba\": y_proba}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c628698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    import numpy as np\n",
    "    \n",
    "    if not isinstance(X_test, np.ndarray):\n",
    "        X_test = X_test.values\n",
    "\n",
    "    print(f\"\\n================= Evaluasi {model_name} =================\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy Score : {acc:.4f}\")\n",
    "    print(f\"Weighted F1    : {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return {\"model\": model_name, \"accuracy\": acc, \"f1_weighted\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be39770",
   "metadata": {},
   "source": [
    "SEMUA MODEL TANPA AKURASI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cac75a",
   "metadata": {},
   "source": [
    "### LightGBM tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c3a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1832\n",
      "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -3.636604\n",
      "[LightGBM] [Info] Start training from score -4.269742\n",
      "[LightGBM] [Info] Start training from score -1.355296\n",
      "[LightGBM] [Info] Start training from score -5.666684\n",
      "[LightGBM] [Info] Start training from score -3.590766\n",
      "[LightGBM] [Info] Start training from score -1.486632\n",
      "[LightGBM] [Info] Start training from score -2.505201\n",
      "[LightGBM] [Info] Start training from score -2.869073\n",
      "[LightGBM] [Info] Start training from score -1.183446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best LGB params: {'subsample': 1.0, 'reg_lambda': 0.01, 'reg_alpha': 0, 'num_leaves': 100, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.03, 'colsample_bytree': 0.8, 'class_weight': 'balanced'}\n",
      "\n",
      "================= Evaluasi lightgbm =================\n",
      "Accuracy Score : 0.8287\n",
      "Weighted F1    : 0.8461\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       119\n",
      "           1       0.55      0.82      0.66       225\n",
      "           2       0.26      1.00      0.41        12\n",
      "           3       1.00      0.78      0.88       911\n",
      "           4       0.92      0.87      0.89       114\n",
      "           5       0.82      1.00      0.90        14\n",
      "           6       0.76      0.97      0.85        39\n",
      "           7       0.69      0.96      0.81        56\n",
      "           8       0.29      0.90      0.44        10\n",
      "\n",
      "    accuracy                           0.83      1500\n",
      "   macro avg       0.70      0.92      0.76      1500\n",
      "weighted avg       0.90      0.83      0.85      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119   0   0   0   0   0   0   0   0]\n",
      " [  0 184  17   0   9   1  10   0   4]\n",
      " [  0   0  12   0   0   0   0   0   0]\n",
      " [  0 148  14 714   0   1   1  17  16]\n",
      " [  0   4   3   0  99   0   0   7   1]\n",
      " [  0   0   0   0   0  14   0   0   0]\n",
      " [  0   0   1   0   0   0  38   0   0]\n",
      " [  0   0   0   0   0   0   1  54   1]\n",
      " [  0   0   0   0   0   1   0   0   9]]\n"
     ]
    }
   ],
   "source": [
    "# Model LightGBM tuning\n",
    "lgb_model = lgb.LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1)\n",
    "\n",
    "param_dist_lgb = {\n",
    "    'num_leaves': [31, 50, 70, 100],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'n_estimators': [100, 300, 600],\n",
    "    'max_depth': [6, 10, 15, -1],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0, 0.01, 0.1],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rsearch_lgb = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist_lgb,\n",
    "    n_iter=20,\n",
    "    scoring='f1_weighted',\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit using numeric features only (LightGBM accepts numpy)\n",
    "rsearch_lgb.fit(X_train_model[features].values, y_train, sample_weight=sample_weight_train)\n",
    "print(\"Best LGB params:\", rsearch_lgb.best_params_)\n",
    "best_lgb = rsearch_lgb.best_estimator_\n",
    "\n",
    "# Evaluate on test\n",
    "res_lgb = evaluate_model(best_lgb, X_test_model[features], y_test, model_name=\"lightgbm\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c173e3",
   "metadata": {},
   "source": [
    "### CatBoost tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddca9049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost dengan params: {'iterations': 400, 'depth': 6, 'learning_rate': 0.05, 'l2_leaf_reg': 3}\n",
      "Val F1-weighted: 0.8369662691233885\n",
      "Training CatBoost dengan params: {'iterations': 600, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 5}\n",
      "Val F1-weighted: 0.8341673489090355\n",
      "Training CatBoost dengan params: {'iterations': 300, 'depth': 10, 'learning_rate': 0.05, 'l2_leaf_reg': 3}\n",
      "Val F1-weighted: 0.8253883126368211\n",
      "Training CatBoost dengan params: {'iterations': 800, 'depth': 8, 'learning_rate': 0.02, 'l2_leaf_reg': 7}\n",
      "Val F1-weighted: 0.833126454586688\n",
      "\n",
      "Best CatBoost val F1: 0.8369662691233885\n",
      "\n",
      "================= Evaluasi catboost =================\n",
      "Accuracy Score : 0.8173\n",
      "Weighted F1    : 0.8357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       119\n",
      "           1       0.55      0.84      0.67       225\n",
      "           2       0.21      0.75      0.33        12\n",
      "           3       1.00      0.77      0.87       911\n",
      "           4       0.91      0.84      0.87       114\n",
      "           5       0.58      1.00      0.74        14\n",
      "           6       0.68      0.97      0.80        39\n",
      "           7       0.69      0.96      0.81        56\n",
      "           8       0.23      0.70      0.34        10\n",
      "\n",
      "    accuracy                           0.82      1500\n",
      "   macro avg       0.65      0.87      0.71      1500\n",
      "weighted avg       0.89      0.82      0.84      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119   0   0   0   0   0   0   0   0]\n",
      " [  0 189  12   0   7   5   8   0   4]\n",
      " [  0   2   9   0   1   0   0   0   0]\n",
      " [  1 143  18 700   0   4   9  17  19]\n",
      " [  0   9   2   0  96   0   0   7   0]\n",
      " [  0   0   0   0   0  14   0   0   0]\n",
      " [  0   0   1   0   0   0  38   0   0]\n",
      " [  0   0   0   0   1   0   0  54   1]\n",
      " [  0   0   0   0   1   1   1   0   7]]\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# FIX DATA KATEGORIK (WAJIB)\n",
    "# =============================\n",
    "# CatBoost tidak boleh ada NaN pada kolom kategori\n",
    "# dan harus bertipe string/objek\n",
    "\n",
    "for c in cat_features:\n",
    "    X_train_model[c] = X_train_model[c].fillna(\"Unknown\").astype(str)\n",
    "    X_val_model[c] = X_val_model[c].fillna(\"Unknown\").astype(str)\n",
    "    X_test_model[c] = X_test_model[c].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Ambil index kolom kategori (lebih aman daripada nama kolom)\n",
    "cat_cols_idx = [X_train_model.columns.get_loc(c) for c in cat_features]\n",
    "\n",
    "\n",
    "# =============================\n",
    "# PARAMETER GRID\n",
    "# =============================\n",
    "cat_params_grid = [\n",
    "    {'iterations': 400, 'depth': 6, 'learning_rate': 0.05, 'l2_leaf_reg': 3},\n",
    "    {'iterations': 600, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 5},\n",
    "    {'iterations': 300, 'depth': 10, 'learning_rate': 0.05, 'l2_leaf_reg': 3},\n",
    "    {'iterations': 800, 'depth': 8, 'learning_rate': 0.02, 'l2_leaf_reg': 7},\n",
    "]\n",
    "\n",
    "\n",
    "# =============================\n",
    "# CATBOOST TRAINING LOOP\n",
    "# =============================\n",
    "best_cat = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for params in cat_params_grid:\n",
    "    print(\"Training CatBoost dengan params:\", params)\n",
    "\n",
    "    model_cb = CatBoostClassifier(\n",
    "        iterations=params['iterations'],\n",
    "        depth=params['depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        loss_function='MultiClass',\n",
    "        thread_count=-1,\n",
    "        class_weights=[class_weights[i] for i in range(len(class_weights))]\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    model_cb.fit(\n",
    "        X_train_model,\n",
    "        y_train,\n",
    "        cat_features=cat_cols_idx,             # gunakan index kolom kategori\n",
    "        eval_set=(X_val_model, y_val),\n",
    "        use_best_model=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Evaluasi\n",
    "    y_val_pred = model_cb.predict(X_val_model)\n",
    "    f1_w = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    print(\"Val F1-weighted:\", f1_w)\n",
    "\n",
    "    if f1_w > best_score:\n",
    "        best_score = f1_w\n",
    "        best_cat = model_cb\n",
    "\n",
    "print(\"\\nBest CatBoost val F1:\", best_score)\n",
    "\n",
    "\n",
    "# =============================\n",
    "# FINAL EVALUATION ON TEST SET\n",
    "# =============================\n",
    "res_cat = evaluate_model(best_cat, X_test_model, y_test, model_name=\"catboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978dd5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model  f1_weighted\n",
      "0  lightgbm     0.846122\n",
      "1  catboost     0.835651\n"
     ]
    }
   ],
   "source": [
    "# AGGREGASI HASIL & SIMPAN MODEL\n",
    "# Collect results\n",
    "results = pd.DataFrame([\n",
    "    {'model': 'lightgbm', 'f1_weighted': res_lgb['f1_weighted']},\n",
    "    {'model': 'catboost', 'f1_weighted': res_cat['f1_weighted']},\n",
    "]).sort_values('f1_weighted', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Save best model (example)\n",
    "best_model_name = results.loc[0, 'model']\n",
    "if best_model_name == 'lightgbm':\n",
    "    joblib.dump(best_lgb, \"best_model_lgb.joblib\")\n",
    "elif best_model_name == 'xgboost':\n",
    "    joblib.dump(best_xgb, \"best_model_xgb.joblib\")\n",
    "else:\n",
    "    best_cat.save_model(\"best_model_catboost.cbm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8ca0c",
   "metadata": {},
   "source": [
    "##### https://chatgpt.com/s/t_691c43865d7c8191bb77a31cb9beba06\n",
    "##### https://chatgpt.com/s/t_691c43ba95048191969c1f1bf9971125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbcca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3715f8",
   "metadata": {},
   "source": [
    "## Cosine Similarity (tidak ada akurasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537de267",
   "metadata": {},
   "source": [
    "#### Pure Cosine Similarity (CONTENT BASED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892b07f",
   "metadata": {},
   "source": [
    "- Tidak menggunakan machine learning.\n",
    "- Menggunakan pendekatan pure similarity berbasis cosine.\n",
    "- Memberikan rekomendasi dengan cara melihat pelanggan yang paling mirip secara perilaku.\n",
    "- Sederhana, cepat, dan cocok sebagai baseline rekomendasi modern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e387c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('General Offer', target_offer\n",
      "General Offer             5\n",
      "Device Upgrade Offer      4\n",
      "Streaming Partner Pack    1\n",
      "Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(\"data/raw/data_capstone.csv\")\n",
    "\n",
    "num_cols = [\n",
    "    'avg_data_usage_gb','pct_video_usage','avg_call_duration',\n",
    "    'sms_freq','monthly_spend','topup_freq','travel_score','complaint_count'\n",
    "]\n",
    "\n",
    "X = df[num_cols]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "sim_matrix = cosine_similarity(X_scaled)\n",
    "\n",
    "def recommend_cosine(target_index, top_k=10):\n",
    "    sims = list(enumerate(sim_matrix[target_index]))\n",
    "    sims = sorted(sims, key=lambda x: x[1], reverse=True)[1:top_k+1]\n",
    "    offers = df.loc[[i for i,_ in sims],'target_offer'].value_counts()\n",
    "    return offers.idxmax(), offers\n",
    "\n",
    "print(recommend_cosine(100,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1688df",
   "metadata": {},
   "source": [
    "#### KNN CLASSIFIER (metric = cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97f537",
   "metadata": {},
   "source": [
    "Model KNN ini:\n",
    "- Menggunakan cosine similarity untuk mencari pelanggan dengan perilaku paling mirip.\n",
    "- Menggunakan 10 tetangga untuk memutuskan offer terbaik.\n",
    "- Memberikan baseline sederhana untuk prediksi target_offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b464eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = df[\"target_offer\"]\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb2894",
   "metadata": {},
   "source": [
    "##### CLUSTERING + COSINE RECOMMENDER\n",
    "###### KMeans (cosine distance via normalized vectors) \n",
    "- Mengelompokkan pelanggan dengan K-Means.\n",
    "- Berdasarkan cluster yang sama ‚Üí menawarkan offer yang paling relevan berdasarkan mayoritas.\n",
    "- Sederhana, cepat, dan cocok untuk baseline rekomendasi berbasis segmentasi pelanggan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6273e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('General Offer', target_offer\n",
      "General Offer             886\n",
      "Device Upgrade Offer      148\n",
      "Roaming Pass               88\n",
      "Top-up Promo               61\n",
      "Streaming Partner Pack     60\n",
      "Data Booster               54\n",
      "Retention Offer            19\n",
      "Voice Bundle                8\n",
      "Family Plan Offer           5\n",
      "Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=8, random_state=42)\n",
    "km.fit(X_scaled)\n",
    "\n",
    "df[\"cluster\"] = km.labels_\n",
    "\n",
    "def recommend_cluster(customer_index):\n",
    "    cl = df.loc[customer_index, \"cluster\"]\n",
    "    offers = df[df[\"cluster\"] == cl][\"target_offer\"].value_counts()\n",
    "    return offers.idxmax(), offers\n",
    "\n",
    "print(recommend_cluster(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f121fb2",
   "metadata": {},
   "source": [
    "#### MATRIX FACTORIZATION + COSINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5a67b",
   "metadata": {},
   "source": [
    "Program ini:\n",
    "- Menggunakan NMF untuk menemukan pola tersembunyi di balik preferensi offer.\n",
    "- Mengubah pelanggan menjadi vektor latent.\n",
    "- Menggunakan cosine similarity untuk mencari pelanggan mirip.\n",
    "- Merekomendasikan offer terbaik berdasarkan perilaku pelanggan serupa.\n",
    "\n",
    "##### Model ini bekerja baik saat data penawaran bersifat kategori dan ingin menemukan pola preferensi tersembunyi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc229f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('General Offer', target_offer\n",
      "General Offer    10\n",
      "Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "mat = pd.get_dummies(df[\"target_offer\"])\n",
    "nmf = NMF(n_components=20, init=\"random\", random_state=42)\n",
    "embed = nmf.fit_transform(mat)\n",
    "\n",
    "sim_latent = cosine_similarity(embed)\n",
    "\n",
    "def recommend_latent(idx, top_k=10):\n",
    "    sims = np.argsort(sim_latent[idx])[::-1][1:top_k+1]\n",
    "    offers = df.iloc[sims][\"target_offer\"].value_counts()\n",
    "    return offers.idxmax(), offers\n",
    "\n",
    "print(recommend_latent(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fca06",
   "metadata": {},
   "source": [
    "#### AUTOENCODER + COSINE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eab491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (2.20.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\Documents\\ASAH 2025\\CAPSTONE\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: namex in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: optree in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f90df8",
   "metadata": {},
   "source": [
    "Program ini membangun Autoencoder untuk:\n",
    "- mengkompres data pelanggan menjadi embedding,\n",
    "- menghitung kemiripan antar pelanggan, dan\n",
    "- akhirnya membuat sistem rekomendasi penawaran berbasis similarity.\n",
    "\n",
    "##### Model ini unggul ketika fitur numerik banyak dan sulit dianalisis secara manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4a99173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "('Device Upgrade Offer', target_offer\n",
      "Device Upgrade Offer      6\n",
      "General Offer             3\n",
      "Streaming Partner Pack    1\n",
      "Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_dim = X_scaled.shape[1]\n",
    "\n",
    "inp = layers.Input(shape=(input_dim,))\n",
    "enc = layers.Dense(32, activation=\"relu\")(inp)\n",
    "emb = layers.Dense(16, activation=\"relu\")(enc)\n",
    "\n",
    "dec = layers.Dense(32, activation=\"relu\")(emb)\n",
    "out = layers.Dense(input_dim)(dec)\n",
    "\n",
    "AE = models.Model(inp, out)\n",
    "encoder = models.Model(inp, emb)\n",
    "\n",
    "AE.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "AE.fit(X_scaled, X_scaled, epochs=30, batch_size=128, verbose=0)\n",
    "\n",
    "embeddings = encoder.predict(X_scaled)\n",
    "sim_emb = cosine_similarity(embeddings)\n",
    "\n",
    "def recommend_ae(idx, top_k=10):\n",
    "    sims = np.argsort(sim_emb[idx])[::-1][1:top_k+1]\n",
    "    offers = df.iloc[sims][\"target_offer\"].value_counts()\n",
    "    return offers.idxmax(), offers\n",
    "\n",
    "print(recommend_ae(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25619bf7",
   "metadata": {},
   "source": [
    "#### https://chatgpt.com/s/t_691c491b5eb08191ae3b5250484ac3ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "884d4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (0.14.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\Documents\\ASAH 2025\\CAPSTONE\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\asus\\documents\\asah 2025\\capstone\\.venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a739ff0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_data_usage_gb</th>\n",
       "      <th>pct_video_usage</th>\n",
       "      <th>avg_call_duration</th>\n",
       "      <th>sms_freq</th>\n",
       "      <th>monthly_spend</th>\n",
       "      <th>topup_freq</th>\n",
       "      <th>travel_score</th>\n",
       "      <th>complaint_count</th>\n",
       "      <th>plan_type_Prepaid</th>\n",
       "      <th>device_brand_Huawei</th>\n",
       "      <th>device_brand_Oppo</th>\n",
       "      <th>device_brand_Realme</th>\n",
       "      <th>device_brand_Samsung</th>\n",
       "      <th>device_brand_Vivo</th>\n",
       "      <th>device_brand_Xiaomi</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.061621</td>\n",
       "      <td>2.046720</td>\n",
       "      <td>-0.486489</td>\n",
       "      <td>-0.521547</td>\n",
       "      <td>-0.860550</td>\n",
       "      <td>0.593283</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>0.796856</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>2.376994</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.159227</td>\n",
       "      <td>-1.507241</td>\n",
       "      <td>-0.147440</td>\n",
       "      <td>-1.552817</td>\n",
       "      <td>-1.011679</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>-1.055531</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>-1.254932</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>2.483401</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.647391</td>\n",
       "      <td>-0.454985</td>\n",
       "      <td>-1.209649</td>\n",
       "      <td>-0.521547</td>\n",
       "      <td>-0.450343</td>\n",
       "      <td>2.347810</td>\n",
       "      <td>0.762691</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>-1.254932</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>2.412867</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152220</td>\n",
       "      <td>0.087267</td>\n",
       "      <td>-0.705368</td>\n",
       "      <td>-1.810634</td>\n",
       "      <td>-0.925319</td>\n",
       "      <td>0.593283</td>\n",
       "      <td>0.125934</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>0.796856</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.964016</td>\n",
       "      <td>-0.772672</td>\n",
       "      <td>0.163712</td>\n",
       "      <td>1.540993</td>\n",
       "      <td>-0.817370</td>\n",
       "      <td>1.178125</td>\n",
       "      <td>1.298936</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>0.796856</td>\n",
       "      <td>2.439882</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_data_usage_gb  pct_video_usage  avg_call_duration  sms_freq  \\\n",
       "0          -1.061621         2.046720          -0.486489 -0.521547   \n",
       "1          -1.159227        -1.507241          -0.147440 -1.552817   \n",
       "2          -0.647391        -0.454985          -1.209649 -0.521547   \n",
       "3          -0.152220         0.087267          -0.705368 -1.810634   \n",
       "4          -0.964016        -0.772672           0.163712  1.540993   \n",
       "\n",
       "   monthly_spend  topup_freq  travel_score  complaint_count  \\\n",
       "0      -0.860550    0.593283      0.013842        -0.699682   \n",
       "1      -1.011679    0.008441     -1.055531        -0.699682   \n",
       "2      -0.450343    2.347810      0.762691        -0.699682   \n",
       "3      -0.925319    0.593283      0.125934        -0.699682   \n",
       "4      -0.817370    1.178125      1.298936        -0.699682   \n",
       "\n",
       "   plan_type_Prepaid  device_brand_Huawei  device_brand_Oppo  \\\n",
       "0           0.796856            -0.409856          -0.399751   \n",
       "1          -1.254932            -0.409856          -0.399751   \n",
       "2          -1.254932            -0.409856          -0.399751   \n",
       "3           0.796856            -0.409856          -0.399751   \n",
       "4           0.796856             2.439882          -0.399751   \n",
       "\n",
       "   device_brand_Realme  device_brand_Samsung  device_brand_Vivo  \\\n",
       "0             2.376994             -0.408663          -0.402674   \n",
       "1            -0.420699             -0.408663           2.483401   \n",
       "2            -0.420699             -0.408663          -0.402674   \n",
       "3            -0.420699             -0.408663          -0.402674   \n",
       "4            -0.420699             -0.408663          -0.402674   \n",
       "\n",
       "   device_brand_Xiaomi  target  \n",
       "0            -0.414445       3  \n",
       "1            -0.414445       3  \n",
       "2             2.412867       3  \n",
       "3            -0.414445       3  \n",
       "4            -0.414445       3  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = pd.read_csv('data/processed/processed_data.csv')\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "732ee3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['avg_data_usage_gb', 'pct_video_usage', 'avg_call_duration', 'sms_freq',\n",
      "       'monthly_spend', 'topup_freq', 'travel_score', 'complaint_count',\n",
      "       'plan_type_Prepaid', 'device_brand_Huawei', 'device_brand_Oppo',\n",
      "       'device_brand_Realme', 'device_brand_Samsung', 'device_brand_Vivo',\n",
      "       'device_brand_Xiaomi', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/processed/processed_data.csv\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc13a9",
   "metadata": {},
   "source": [
    "Kode ini berfungsi sebagai pipeline pra-pemrosesan dan evaluasi:\n",
    "- Memuat dataset final\n",
    "- Menormalisasi fitur numerik\n",
    "- Meng-encode label target\n",
    "- Membagi data train & test\n",
    "- Menyediakan fungsi evaluasi yang lengkap (Accuracy, F1, Report, Confusion Matrix, ROC-AUC)\n",
    "#####  ‚Üí Anda dapat langsung melatih model apa pun dan menggunakan eval_metrics() untuk mengukur performanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50663e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import (\n",
    "    f1_score, classification_report, confusion_matrix,\n",
    "    roc_auc_score, accuracy_score\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 1Ô∏è‚É£ LOAD FINAL DATASET\n",
    "# =========================================================\n",
    "df = pd.read_csv(\"data/processed/processed_data.csv\")   # FINAL VERSION\n",
    "\n",
    "target_col = \"target\"\n",
    "\n",
    "numerical_cols = [\n",
    "    'avg_data_usage_gb','pct_video_usage','avg_call_duration',\n",
    "    'sms_freq','monthly_spend','topup_freq','travel_score','complaint_count'\n",
    "]\n",
    "\n",
    "X = df[numerical_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# =========================================================\n",
    "# 2Ô∏è‚É£ NORMALISASI + LABEL ENCODING\n",
    "# =========================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3Ô∏è‚É£ FUNGSI EVALUASI ‚Üí WAJIB‚Äº\n",
    "# =========================================================\n",
    "def eval_metrics(y_true, y_pred, y_pred_proba):\n",
    "    print(\"\\nüìå ACCURACY:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"\\nüìå F1-Weighted:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "    print(\"\\nüìå CLASS REPORT:\\n\", classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "    print(\"\\nüìå CONFUSION MATRIX:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nüìå ROC-AUC:\", roc_auc_score(y_true, y_pred_proba, multi_class='ovr'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87c81945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: data/processed/processed_data.csv\n",
      "Using target column: target\n",
      "Using expected numeric columns.\n",
      "\n",
      "=== Running Model 1: Pure Cosine ===\n",
      "Accuracy: 0.7415557830092119\n",
      "F1 (weighted): 0.705969021812627\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       157\n",
      "           1       0.53      0.46      0.50       293\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.78      0.90      0.83      1185\n",
      "           4       0.79      0.72      0.75       148\n",
      "           5       1.00      0.06      0.11        18\n",
      "           6       0.44      0.08      0.13        51\n",
      "           7       0.00      0.00      0.00        73\n",
      "           8       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.74      1954\n",
      "   macro avg       0.48      0.34      0.35      1954\n",
      "weighted avg       0.69      0.74      0.71      1954\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 136    6    0   12    2    0    1    0    0]\n",
      " [  20  136    0  124   11    0    2    0    0]\n",
      " [   0    4    0   11    0    0    1    0    0]\n",
      " [  14   96    0 1065    9    0    1    0    0]\n",
      " [   0    9    0   31  107    0    0    1    0]\n",
      " [   0    1    0   16    0    1    0    0    0]\n",
      " [   7    1    0   39    0    0    4    0    0]\n",
      " [   0    0    0   66    7    0    0    0    0]\n",
      " [   1    2    0   10    0    0    0    0    0]]\n",
      "ROC-AUC (ovr): 0.9400076804541988\n",
      "\n",
      "=== Running Model 2: KNN (cosine) ===\n",
      "Accuracy: 0.7436028659160696\n",
      "F1 (weighted): 0.7200217617920339\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       157\n",
      "           1       0.50      0.46      0.48       293\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.80      0.89      0.84      1185\n",
      "           4       0.77      0.78      0.78       148\n",
      "           5       0.50      0.11      0.18        18\n",
      "           6       0.44      0.24      0.31        51\n",
      "           7       0.58      0.10      0.16        73\n",
      "           8       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.74      1954\n",
      "   macro avg       0.54      0.39      0.41      1954\n",
      "weighted avg       0.72      0.74      0.72      1954\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 129   12    0    7    4    1    4    0    0]\n",
      " [  20  135    0  120   11    0    7    0    0]\n",
      " [   2    5    0    8    0    0    1    0    0]\n",
      " [  10  104    0 1051   13    1    3    3    0]\n",
      " [   0    9    0   22  116    0    0    1    0]\n",
      " [   0    2    0   14    0    2    0    0    0]\n",
      " [   8    1    0   30    0    0   12    0    0]\n",
      " [   0    0    0   59    6    0    0    7    1]\n",
      " [   0    1    0   10    0    0    0    1    1]]\n",
      "ROC-AUC (ovr): 0.9024504079040797\n",
      "\n",
      "=== Running Model 3: KMeans Clustering ===\n",
      "Accuracy: 0.6811668372569089\n",
      "F1 (weighted): 0.6235759041936914\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       157\n",
      "           1       0.38      0.54      0.45       293\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.76      0.89      0.82      1185\n",
      "           4       0.75      0.83      0.79       148\n",
      "           5       0.00      0.00      0.00        18\n",
      "           6       0.00      0.00      0.00        51\n",
      "           7       0.00      0.00      0.00        73\n",
      "           8       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.68      1954\n",
      "   macro avg       0.21      0.25      0.23      1954\n",
      "weighted avg       0.58      0.68      0.62      1954\n",
      "\n",
      "Confusion matrix:\n",
      "[[   0  107    0   37   13    0    0    0    0]\n",
      " [   0  157    0  116   20    0    0    0    0]\n",
      " [   0    3    0   13    0    0    0    0    0]\n",
      " [   0  134    0 1051    0    0    0    0    0]\n",
      " [   0    5    0   20  123    0    0    0    0]\n",
      " [   0    0    0   18    0    0    0    0    0]\n",
      " [   0    0    0   51    0    0    0    0    0]\n",
      " [   0    0    0   66    7    0    0    0    0]\n",
      " [   0    3    0   10    0    0    0    0    0]]\n",
      "ROC-AUC (ovr): 0.8252097960901469\n",
      "\n",
      "=== Running Model 4: NMF Embedding ===\n",
      "Accuracy: 0.6709314227226203\n",
      "F1 (weighted): 0.6138888630650573\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.36      0.42       157\n",
      "           1       0.45      0.24      0.31       293\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.69      0.92      0.79      1185\n",
      "           4       0.79      0.59      0.68       148\n",
      "           5       0.00      0.00      0.00        18\n",
      "           6       0.00      0.00      0.00        51\n",
      "           7       0.00      0.00      0.00        73\n",
      "           8       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.67      1954\n",
      "   macro avg       0.27      0.24      0.25      1954\n",
      "weighted avg       0.59      0.67      0.61      1954\n",
      "\n",
      "Confusion matrix:\n",
      "[[  56   23    0   75    3    0    0    0    0]\n",
      " [  28   71    0  189    5    0    0    0    0]\n",
      " [   1    0    0   15    0    0    0    0    0]\n",
      " [  22   57    0 1096   10    0    0    0    0]\n",
      " [   0    7    0   53   88    0    0    0    0]\n",
      " [   0    0    0   18    0    0    0    0    0]\n",
      " [   0    0    0   51    0    0    0    0    0]\n",
      " [   0    0    0   68    5    0    0    0    0]\n",
      " [   0    0    0   13    0    0    0    0    0]]\n",
      "ROC-AUC (ovr): 0.8549238934166976\n",
      "\n",
      "=== Running Model 5: Hybrid Cosine Features + (CatBoost/XGBoost) ===\n",
      "0:\tlearn: 1.9577755\ttest: 1.9620653\tbest: 1.9620653 (0)\ttotal: 613ms\tremaining: 6m 7s\n",
      "100:\tlearn: 0.3226567\ttest: 0.3527849\tbest: 0.3527849 (100)\ttotal: 26.4s\tremaining: 2m 10s\n",
      "200:\tlearn: 0.2555587\ttest: 0.3200299\tbest: 0.3200299 (200)\ttotal: 59.5s\tremaining: 1m 58s\n",
      "300:\tlearn: 0.2141784\ttest: 0.3087879\tbest: 0.3085858 (289)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "400:\tlearn: 0.1849085\ttest: 0.3065415\tbest: 0.3065415 (400)\ttotal: 1m 41s\tremaining: 50.2s\n",
      "500:\tlearn: 0.1635111\ttest: 0.3067325\tbest: 0.3059015 (471)\ttotal: 1m 59s\tremaining: 23.6s\n",
      "599:\tlearn: 0.1450190\ttest: 0.3079745\tbest: 0.3059015 (471)\ttotal: 2m 17s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3059014927\n",
      "bestIteration = 471\n",
      "\n",
      "Shrink model to first 472 iterations.\n",
      "[INFO] Trained CatBoost hybrid model.\n",
      "Accuracy: 0.8300921187308086\n",
      "F1 (weighted): 0.8321162031397918\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       157\n",
      "           1       0.55      0.73      0.63       293\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.91      0.86      0.88      1185\n",
      "           4       0.93      0.88      0.90       148\n",
      "           5       0.89      0.89      0.89        18\n",
      "           6       0.88      0.73      0.80        51\n",
      "           7       0.65      0.75      0.70        73\n",
      "           8       0.17      0.08      0.11        13\n",
      "\n",
      "    accuracy                           0.83      1954\n",
      "   macro avg       0.66      0.65      0.65      1954\n",
      "weighted avg       0.84      0.83      0.83      1954\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 154    0    0    1    1    1    0    0    0]\n",
      " [   4  214    0   68    3    0    4    0    0]\n",
      " [   0    8    0    7    0    0    1    0    0]\n",
      " [   0  144    1 1015    0    1    0   23    1]\n",
      " [   0   12    1    0  130    0    0    5    0]\n",
      " [   0    0    0    0    2   16    0    0    0]\n",
      " [   1   11    0    1    0    0   37    0    1]\n",
      " [   0    0    0   11    4    0    0   55    3]\n",
      " [   0    0    0   11    0    0    0    1    1]]\n",
      "ROC-AUC (ovr): 0.9832564663415295\n",
      "[INFO] Saved hybrid model to /mnt/data/models/\n",
      "\n",
      "=== Running Model 6: Autoencoder Embedding ===\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "Accuracy: 0.7456499488229273\n",
      "F1 (weighted): 0.7064807811052539\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       157\n",
      "           1       0.55      0.43      0.48       293\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.77      0.91      0.83      1185\n",
      "           4       0.83      0.74      0.78       148\n",
      "           5       1.00      0.06      0.11        18\n",
      "           6       0.33      0.04      0.07        51\n",
      "           7       0.00      0.00      0.00        73\n",
      "           8       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.75      1954\n",
      "   macro avg       0.48      0.34      0.34      1954\n",
      "weighted avg       0.69      0.75      0.71      1954\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 134    8    0   12    2    0    1    0    0]\n",
      " [  13  127    0  140   11    0    2    0    0]\n",
      " [   0    4    0   12    0    0    0    0    0]\n",
      " [  12   84    0 1084    4    0    1    0    0]\n",
      " [   0    8    0   30  109    0    0    1    0]\n",
      " [   0    0    0   17    0    1    0    0    0]\n",
      " [   7    0    0   42    0    0    2    0    0]\n",
      " [   0    0    0   68    5    0    0    0    0]\n",
      " [   1    1    0   11    0    0    0    0    0]]\n",
      "ROC-AUC (ovr): 0.9405150781479037\n",
      "\n",
      "=== Summary of results ===\n",
      "PureCosine -> {'accuracy': 0.7415557830092119, 'f1_weighted': 0.705969021812627, 'roc_auc': 0.9400076804541988}\n",
      "KNN_Cosine -> {'accuracy': 0.7436028659160696, 'f1_weighted': 0.7200217617920339, 'roc_auc': 0.9024504079040797}\n",
      "KMeans_ClusterMajor -> {'accuracy': 0.6811668372569089, 'f1_weighted': 0.6235759041936914, 'roc_auc': 0.8252097960901469}\n",
      "NMF_Embedding -> {'accuracy': 0.6709314227226203, 'f1_weighted': 0.6138888630650573, 'roc_auc': 0.8549238934166976}\n",
      "Hybrid_CB_XGB -> {'accuracy': 0.8300921187308086, 'f1_weighted': 0.8321162031397918, 'roc_auc': 0.9832564663415295}\n",
      "Autoencoder_AE -> {'accuracy': 0.7456499488229273, 'f1_weighted': 0.7064807811052539, 'roc_auc': 0.9405150781479037}\n",
      "\n",
      "Pipeline finished. Models (if trained) saved to /mnt/data/models\n"
     ]
    }
   ],
   "source": [
    "# Final Cosine Pipeline (one-cell)\n",
    "# Paste and run in Jupyter/Colab. Adjust install commands if needed.\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Helper: Try common dataset paths\n",
    "# -------------------------\n",
    "possible_paths = [\n",
    "    \"data/processed/processed_data.csv\",\n",
    "    \"data/raw/data_capstone.csv\",\n",
    "    \"data/processed/processed_data.csv\",\n",
    "    \"data/raw/data_capstone.csv\",\n",
    "    \"processed_data.csv\",\n",
    "    \"data_capstone.csv\"\n",
    "]\n",
    "\n",
    "df_path = None\n",
    "for p in possible_paths:\n",
    "    if os.path.exists(p):\n",
    "        df_path = p\n",
    "        break\n",
    "\n",
    "if df_path is None:\n",
    "    raise FileNotFoundError(f\"Dataset not found. Checked: {possible_paths}\")\n",
    "\n",
    "print(\"Loading dataset from:\", df_path)\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# -------------------------\n",
    "# Identify target column\n",
    "# If user uses different name, try common names\n",
    "# -------------------------\n",
    "possible_targets = [\"target_offer\", \"target\", \"offer\", \"label\", \"target_label\"]\n",
    "target_col = None\n",
    "for t in possible_targets:\n",
    "    if t in df.columns:\n",
    "        target_col = t\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    # fallback: choose last column if likely categorical\n",
    "    cand = df.columns[-1]\n",
    "    if df[cand].dtype == object or len(df[cand].unique()) < 50:\n",
    "        target_col = cand\n",
    "        print(f\"[WARN] target not found in common names; using last column: '{target_col}'\")\n",
    "    else:\n",
    "        raise KeyError(\"Target column not found. Expected one of \"\n",
    "                       f\"{possible_targets}. Columns: {list(df.columns)}\")\n",
    "\n",
    "print(\"Using target column:\", target_col)\n",
    "\n",
    "# -------------------------\n",
    "# Numeric features (expected)\n",
    "# -------------------------\n",
    "numerical_cols = [\n",
    "    'avg_data_usage_gb','pct_video_usage','avg_call_duration',\n",
    "    'sms_freq','monthly_spend','topup_freq','travel_score','complaint_count'\n",
    "]\n",
    "\n",
    "# Safety: if any missing numeric col, attempt to auto-detect numeric features\n",
    "missing = [c for c in numerical_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"[WARN] Some expected numeric columns missing: {missing}\")\n",
    "    # auto-select numeric columns except the target and id-like columns\n",
    "    auto_numeric = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # remove target if numeric\n",
    "    auto_numeric = [c for c in auto_numeric if c != target_col]\n",
    "    # choose up to 8 numeric features (prefer previously listed if present)\n",
    "    final_numeric = [c for c in numerical_cols if c in df.columns] + [c for c in auto_numeric if c not in numerical_cols]\n",
    "    numerical_cols = final_numeric[:8]\n",
    "    print(\"Auto-selected numeric columns:\", numerical_cols)\n",
    "else:\n",
    "    print(\"Using expected numeric columns.\")\n",
    "\n",
    "# ensure we have at least 2 numeric features\n",
    "if len(numerical_cols) < 2:\n",
    "    raise ValueError(\"Not enough numeric features for similarity. Columns found: \" + str(numerical_cols))\n",
    "\n",
    "X = df[numerical_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# -------------------------\n",
    "# Preprocessing & splits\n",
    "# -------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "# maintain indices for mapping predictions computed across full DF\n",
    "indices = np.arange(len(df))\n",
    "\n",
    "# train/test split for supervised evaluation\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X_scaled, y_enc, indices, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation helper (robust)\n",
    "# -------------------------\n",
    "def eval_metrics(y_true, y_pred, y_proba, label_encoder=le):\n",
    "    \"\"\"y_true, y_pred are integer-encoded labels; y_proba shape (n_samples, n_classes)\"\"\"\n",
    "    # convert label names to strings to avoid sklearn errors\n",
    "    tn = [str(c) for c in label_encoder.classes_]\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1w = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1 (weighted):\", f1w)\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=tn))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_proba, multi_class='ovr')\n",
    "    except Exception as e:\n",
    "        auc = f\"ROC-AUC error: {e}\"\n",
    "    print(\"ROC-AUC (ovr):\", auc)\n",
    "    return {\"accuracy\": acc, \"f1_weighted\": f1w, \"roc_auc\": auc}\n",
    "\n",
    "# helper: convert counts Series -> proba vector aligned to label encoder\n",
    "def series_to_proba_vector(counts_series, label_encoder=le):\n",
    "    probs = np.zeros(len(label_encoder.classes_), dtype=float)\n",
    "    if counts_series is None or len(counts_series)==0:\n",
    "        # uniform small prob\n",
    "        probs += 1.0 / len(probs)\n",
    "        return probs\n",
    "    for lab, val in counts_series.items():\n",
    "        try:\n",
    "            idx = list(label_encoder.classes_).index(lab)\n",
    "            probs[idx] = val\n",
    "        except ValueError:\n",
    "            # if stored labels are encoded numbers, try convert\n",
    "            try:\n",
    "                lab_int = int(lab)\n",
    "                labname = label_encoder.inverse_transform([lab_int])[0]\n",
    "                idx = list(label_encoder.classes_).index(labname)\n",
    "                probs[idx] = val\n",
    "            except Exception:\n",
    "                continue\n",
    "    s = probs.sum()\n",
    "    if s > 0:\n",
    "        probs = probs / s\n",
    "    else:\n",
    "        probs += 1.0 / len(probs)\n",
    "    return probs\n",
    "\n",
    "# -------------------------\n",
    "# Precompute full-similarity matrix once\n",
    "# -------------------------\n",
    "sim_matrix = cosine_similarity(X_scaled)\n",
    "\n",
    "# We'll store results summary\n",
    "results = []\n",
    "\n",
    "# -------------------------\n",
    "# Model 1: Pure Cosine Majority from Top-K (predictions for full df; evaluate on test subset)\n",
    "# -------------------------\n",
    "def predict_cosine_full(top_k=40):\n",
    "    labels = []\n",
    "    probas = []\n",
    "    for i in range(len(df)):\n",
    "        sims = list(enumerate(sim_matrix[i]))\n",
    "        sims = sorted(sims, key=lambda x: x[1], reverse=True)[1:top_k+1]\n",
    "        neigh_idx = [x[0] for x in sims]\n",
    "        counts = df.iloc[neigh_idx][target_col].value_counts()\n",
    "        proba = series_to_proba_vector(counts)\n",
    "        label = np.argmax(proba)\n",
    "        labels.append(label)\n",
    "        probas.append(proba)\n",
    "    return np.array(labels), np.vstack(probas)\n",
    "\n",
    "print(\"\\n=== Running Model 1: Pure Cosine ===\")\n",
    "y_pred_full_cosine, y_proba_full_cosine = predict_cosine_full(top_k=40)\n",
    "# Evaluate on test set indices\n",
    "ytest_true = y_enc[idx_test]\n",
    "ytest_pred = y_pred_full_cosine[idx_test]\n",
    "ytest_proba = y_proba_full_cosine[idx_test]\n",
    "res1 = eval_metrics(ytest_true, ytest_pred, ytest_proba)\n",
    "results.append((\"PureCosine\", res1))\n",
    "\n",
    "# -------------------------\n",
    "# Model 2: KNN (metric='cosine') - supervised\n",
    "# -------------------------\n",
    "print(\"\\n=== Running Model 2: KNN (cosine) ===\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=15, metric=\"cosine\", weights=\"distance\", n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_proba_knn = knn.predict_proba(X_test)\n",
    "res2 = eval_metrics(y_test, y_pred_knn, y_proba_knn)\n",
    "results.append((\"KNN_Cosine\", res2))\n",
    "\n",
    "# -------------------------\n",
    "# Model 3: KMeans clustering -> cluster-majority offer\n",
    "# -------------------------\n",
    "print(\"\\n=== Running Model 3: KMeans Clustering ===\")\n",
    "from sklearn.cluster import KMeans\n",
    "k_clusters = max(2, len(le.classes_))\n",
    "kmeans = KMeans(n_clusters=k_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "df[\"_cluster\"] = clusters\n",
    "cluster_major = df.groupby(\"_cluster\")[target_col].agg(lambda s: s.value_counts().idxmax())\n",
    "\n",
    "# predictions for full df\n",
    "y_pred_cluster_full = []\n",
    "y_proba_cluster_full = []\n",
    "for c in clusters:\n",
    "    counts = df[df[\"_cluster\"]==c][target_col].value_counts(normalize=True)\n",
    "    y_proba_cluster_full.append(series_to_proba_vector(counts))\n",
    "    y_pred_cluster_full.append(np.argmax(series_to_proba_vector(counts)))\n",
    "y_pred_cluster_full = np.array(y_pred_cluster_full)\n",
    "y_proba_cluster_full = np.vstack(y_proba_cluster_full)\n",
    "\n",
    "# evaluate on test subset\n",
    "ytest_pred_cluster = y_pred_cluster_full[idx_test]\n",
    "ytest_proba_cluster = y_proba_cluster_full[idx_test]\n",
    "res3 = eval_metrics(ytest_true, ytest_pred_cluster, ytest_proba_cluster)\n",
    "results.append((\"KMeans_ClusterMajor\", res3))\n",
    "\n",
    "# -------------------------\n",
    "# Model 4: NMF embedding + cosine on embedding\n",
    "# -------------------------\n",
    "print(\"\\n=== Running Model 4: NMF Embedding ===\")\n",
    "from sklearn.decomposition import NMF\n",
    "# choose components <= n_features\n",
    "n_features = X_scaled.shape[1]\n",
    "nmf_components = min(6, n_features)\n",
    "# NMF needs non-negative input; use shifting to positive\n",
    "X_nmf_input = X_scaled - X_scaled.min() + 1e-6\n",
    "nmf = NMF(n_components=nmf_components, init=\"nndsvd\", random_state=42, max_iter=500)\n",
    "emb_nmf = nmf.fit_transform(X_nmf_input)\n",
    "sim_emb_nmf = cosine_similarity(emb_nmf)\n",
    "\n",
    "def predict_nmf_full(top_k=40):\n",
    "    labels = []\n",
    "    probas = []\n",
    "    for i in range(len(df)):\n",
    "        sims = np.argsort(sim_emb_nmf[i])[-(top_k+1):-1]  # exclude itself\n",
    "        neigh_idx = sims\n",
    "        counts = df.iloc[neigh_idx][target_col].value_counts()\n",
    "        proba = series_to_proba_vector(counts)\n",
    "        labels.append(np.argmax(proba))\n",
    "        probas.append(proba)\n",
    "    return np.array(labels), np.vstack(probas)\n",
    "\n",
    "y_pred_nmf_full, y_proba_nmf_full = predict_nmf_full(top_k=40)\n",
    "ytest_pred_nmf = y_pred_nmf_full[idx_test]\n",
    "ytest_proba_nmf = y_proba_nmf_full[idx_test]\n",
    "res4 = eval_metrics(ytest_true, ytest_pred_nmf, ytest_proba_nmf)\n",
    "results.append((\"NMF_Embedding\", res4))\n",
    "\n",
    "# -------------------------\n",
    "# Model 5: Hybrid Cosine Features + CatBoost / XGBoost\n",
    "# -------------------------\n",
    "print(\"\\n=== Running Model 5: Hybrid Cosine Features + (CatBoost/XGBoost) ===\")\n",
    "def build_cosine_offer_features(sim_mtx, k=40):\n",
    "    feat = np.zeros((sim_mtx.shape[0], len(le.classes_)))\n",
    "    for i in range(sim_mtx.shape[0]):\n",
    "        neigh = np.argsort(sim_mtx[i])[-(k+1):]\n",
    "        neigh = neigh[neigh != i]\n",
    "        neigh = neigh[-k:]\n",
    "        counts = df.iloc[neigh][target_col].value_counts(normalize=True)\n",
    "        feat[i,:] = series_to_proba_vector(counts)\n",
    "    return feat\n",
    "\n",
    "sim_feat = build_cosine_offer_features(sim_matrix, k=40)\n",
    "X_hybrid = np.hstack([X_scaled, sim_feat])\n",
    "\n",
    "Xh_tr, Xh_te, yh_tr, yh_te, idxh_tr, idxh_te = train_test_split(\n",
    "    X_hybrid, y_enc, indices, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "model_hybrid = None\n",
    "y_pred_hybrid = None\n",
    "y_proba_hybrid = None\n",
    "\n",
    "# Try CatBoost\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    model_cb = CatBoostClassifier(iterations=600, depth=8, learning_rate=0.05, loss_function=\"MultiClass\", verbose=100)\n",
    "    model_cb.fit(Xh_tr, yh_tr, eval_set=(Xh_te, yh_te))\n",
    "    model_hybrid = model_cb\n",
    "    y_pred_hybrid = model_cb.predict(Xh_te)\n",
    "    y_proba_hybrid = model_cb.predict_proba(Xh_te)\n",
    "    print(\"[INFO] Trained CatBoost hybrid model.\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] CatBoost failed or not installed:\", e)\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        model_xgb = xgb.XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, use_label_encoder=False, eval_metric='mlogloss')\n",
    "        model_xgb.fit(Xh_tr, yh_tr, eval_set=[(Xh_te, yh_te)], verbose=100)\n",
    "        model_hybrid = model_xgb\n",
    "        y_pred_hybrid = model_xgb.predict(Xh_te)\n",
    "        y_proba_hybrid = model_xgb.predict_proba(Xh_te)\n",
    "        print(\"[INFO] Trained XGBoost hybrid model.\")\n",
    "    except Exception as e2:\n",
    "        print(\"[ERROR] Both CatBoost and XGBoost unavailable/failed:\", e2)\n",
    "\n",
    "if model_hybrid is not None and y_pred_hybrid is not None:\n",
    "    res5 = eval_metrics(yh_te, y_pred_hybrid, y_proba_hybrid)\n",
    "    results.append((\"Hybrid_CB_XGB\", res5))\n",
    "    # save model\n",
    "    os.makedirs(\"/mnt/data/models\", exist_ok=True)\n",
    "    try:\n",
    "        # CatBoost has save_model; XGBoost has save_model too\n",
    "        if hasattr(model_hybrid, \"save_model\"):\n",
    "            model_hybrid.save_model(\"/mnt/data/models/hybrid_model.bin\")\n",
    "        else:\n",
    "            import joblib\n",
    "            joblib.dump(model_hybrid, \"/mnt/data/models/hybrid_model.joblib\")\n",
    "        print(\"[INFO] Saved hybrid model to /mnt/data/models/\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Save model failed:\", e)\n",
    "else:\n",
    "    print(\"[WARN] Hybrid model training skipped due to missing libs.\")\n",
    "\n",
    "# -------------------------\n",
    "# Model 6: Autoencoder embedding + cosine\n",
    "# -------------------------\n",
    "print(\"\\n=== Running Model 6: Autoencoder Embedding ===\")\n",
    "ae_success = False\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, Model, callbacks\n",
    "\n",
    "    input_dim = X_scaled.shape[1]\n",
    "    encoding_dim = min(32, input_dim*2)\n",
    "\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(128, activation='relu')(inp)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    encoded = layers.Dense(encoding_dim, activation='relu', name='embed')(x)\n",
    "    x = layers.Dense(64, activation='relu')(encoded)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    decoded = layers.Dense(input_dim, activation='linear')(x)\n",
    "\n",
    "    ae = Model(inp, decoded)\n",
    "    encoder = Model(inp, encoded)\n",
    "    ae.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor='loss', patience=8, restore_best_weights=True)\n",
    "    ae.fit(X_scaled, X_scaled, epochs=60, batch_size=128, callbacks=[es], verbose=0)\n",
    "\n",
    "    emb_ae = encoder.predict(X_scaled)\n",
    "    sim_emb_ae = cosine_similarity(emb_ae)\n",
    "\n",
    "    y_pred_ae_full = []\n",
    "    y_proba_ae_full = []\n",
    "    for i in range(len(df)):\n",
    "        sims = np.argsort(sim_emb_ae[i])[-40-1:-1]\n",
    "        counts = df.iloc[sims][target_col].value_counts()\n",
    "        proba = series_to_proba_vector(counts)\n",
    "        y_proba_ae_full.append(proba)\n",
    "        y_pred_ae_full.append(np.argmax(proba))\n",
    "    y_pred_ae_full = np.array(y_pred_ae_full)\n",
    "    y_proba_ae_full = np.vstack(y_proba_ae_full)\n",
    "\n",
    "    ytest_pred_ae = y_pred_ae_full[idx_test]\n",
    "    ytest_proba_ae = y_proba_ae_full[idx_test]\n",
    "    res6 = eval_metrics(ytest_true, ytest_pred_ae, ytest_proba_ae)\n",
    "    results.append((\"Autoencoder_AE\", res6))\n",
    "    ae_success = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Autoencoder step failed:\", e)\n",
    "\n",
    "# -------------------------\n",
    "# Summary\n",
    "# -------------------------\n",
    "print(\"\\n=== Summary of results ===\")\n",
    "for name, met in results:\n",
    "    print(name, \"->\", met)\n",
    "print(\"\\nPipeline finished. Models (if trained) saved to /mnt/data/models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9366288",
   "metadata": {},
   "source": [
    "https://chatgpt.com/s/t_691d611fdff881918f0e371174d83550"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ae335",
   "metadata": {},
   "source": [
    "CatBoost (Data Murni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94314f",
   "metadata": {},
   "source": [
    "1. Memuat dataset Telco.\n",
    "2. Mendeteksi fitur kategori secara otomatis.\n",
    "3. Membuat Pool CatBoost yang optimal.\n",
    "4. Menghitung class weight agar seimbang.\n",
    "5. Melatih model CatBoost high-accuracy (depth 8, iterations 1500).\n",
    "6. Menghasilkan evaluasi lengkap (F1, AUC, Confusion Matrix).\n",
    "7. Menyimpan model siap pakai untuk produksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26f0df5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features: ['customer_id', 'plan_type', 'device_brand']\n",
      "Numeric Features: ['avg_data_usage_gb', 'pct_video_usage', 'avg_call_duration', 'sms_freq', 'monthly_spend', 'topup_freq', 'travel_score', 'complaint_count']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load dataset raw Telco\n",
    "df = pd.read_csv(\"data/raw/data_capstone.csv\")\n",
    "\n",
    "# Target\n",
    "target = \"target_offer\"\n",
    "\n",
    "# Fitur\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Identifikasi categorical features otomatis\n",
    "cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical Features:\", cat_features)\n",
    "print(\"Numeric Features:\", numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4336dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c503ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_features:\n",
    "    X_train[c] = X_train[c].astype(\"category\")\n",
    "    X_test[c] = X_test[c].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "test_pool = Pool(X_test, y_test, cat_features=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bf2ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1\",        # optimasi F1 langsung\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    iterations=1500,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    class_weights='Balanced',     # menangani imbalance\n",
    "    task_type=\"CPU\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaced701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8735410\ttotal: 759ms\tremaining: 18m 58s\n",
      "200:\tlearn: 0.9986058\ttotal: 1m 42s\tremaining: 11m 1s\n",
      "400:\tlearn: 0.9992868\ttotal: 3m 18s\tremaining: 9m 3s\n",
      "600:\tlearn: 0.9995871\ttotal: 4m 55s\tremaining: 7m 22s\n",
      "800:\tlearn: 0.9996100\ttotal: 6m 34s\tremaining: 5m 43s\n",
      "1000:\tlearn: 0.9997253\ttotal: 8m 11s\tremaining: 4m 5s\n",
      "1200:\tlearn: 0.9997482\ttotal: 9m 50s\tremaining: 2m 27s\n",
      "1400:\tlearn: 0.9997482\ttotal: 11m 33s\tremaining: 49s\n",
      "1499:\tlearn: 0.9997482\ttotal: 12m 22s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b54b9d5720>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "import numpy as np\n",
    "\n",
    "# Hitung class_weights berdasarkan distribusi kelas\n",
    "class_counts = y_train.value_counts().sort_index()\n",
    "class_weights = (1 / class_counts).values\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "test_pool  = Pool(X_test,  y_test,  cat_features=cat_features)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1\",\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    iterations=1500,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "\n",
    "model.fit(train_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eec7180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8735410\ttotal: 585ms\tremaining: 14m 37s\n",
      "200:\tlearn: 0.9986058\ttotal: 1m 37s\tremaining: 10m 29s\n",
      "400:\tlearn: 0.9992868\ttotal: 3m 13s\tremaining: 8m 51s\n",
      "600:\tlearn: 0.9995871\ttotal: 4m 50s\tremaining: 7m 15s\n",
      "800:\tlearn: 0.9996100\ttotal: 6m 28s\tremaining: 5m 38s\n",
      "1000:\tlearn: 0.9997253\ttotal: 8m 6s\tremaining: 4m 2s\n",
      "1200:\tlearn: 0.9997482\ttotal: 9m 51s\tremaining: 2m 27s\n",
      "1400:\tlearn: 0.9997482\ttotal: 11m 30s\tremaining: 48.8s\n",
      "1499:\tlearn: 0.9997482\ttotal: 12m 19s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b54b9d5720>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23cd7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_pool)\n",
    "y_pred_int = np.argmax(model.predict_proba(test_pool), axis=1)\n",
    "y_test_int = y_test.astype(\"category\").cat.codes.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "557491bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1: 0.9932208933549366\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test_int, y_pred_int, average=\"weighted\")\n",
    "print(\"Weighted F1:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43331c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       159\n",
      "           1       1.00      0.99      0.99       300\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      0.99      1.00      1214\n",
      "           4       1.00      0.99      1.00       152\n",
      "           5       0.76      1.00      0.86        19\n",
      "           6       0.95      1.00      0.97        52\n",
      "           7       1.00      0.99      0.99        74\n",
      "           8       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.96      0.99      0.97      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_int, y_pred_int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 158    1    0    0    0    0    0    0    0]\n",
      " [   1  297    0    0    0    2    0    0    0]\n",
      " [   0    0   16    0    0    0    0    0    0]\n",
      " [   2    0    0 1207    0    2    3    0    0]\n",
      " [   0    0    0    0  151    0    0    0    1]\n",
      " [   0    0    0    0    0   19    0    0    0]\n",
      " [   0    0    0    0    0    0   52    0    0]\n",
      " [   0    0    0    0    0    1    0   73    0]\n",
      " [   0    0    0    0    0    1    0    0   13]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_int, y_pred_int)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ac041",
   "metadata": {},
   "source": [
    "###### ROC-AUC Multi-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "624e4ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (OVR): 0.9997942979921588\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(test_pool)\n",
    "auc = roc_auc_score(y_test_int, y_pred_proba, multi_class='ovr')\n",
    "print(\"ROC-AUC (OVR):\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "626ac873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as catboost_telco_best.cbm\n"
     ]
    }
   ],
   "source": [
    "# Simpan Model\n",
    "model.save_model(\"catboost_telco_best.cbm\")\n",
    "print(\"Model saved as catboost_telco_best.cbm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c277872",
   "metadata": {},
   "source": [
    "# CatBoost Menggunakan data_capstone.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf36ac",
   "metadata": {},
   "source": [
    "Versi paling akurat\n",
    "1. ‚úî Memakai Pool ‚Üí kategori diproses optimal\n",
    "2. ‚úî Menggunakan konfigurasi lebih kuat\n",
    "3. ‚úî Laporan evaluasi lebih mudah dibaca\n",
    "\n",
    "- Tidak overfitting secara umum, karena skor test masih sangat tinggi dan stabil.\n",
    "- Yang terjadi adalah ketidakseimbangan data, sehingga kelas kecil tidak bisa dipelajari dengan baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27a6d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "‚ö° CATBOOST EVALUATION METRICS\n",
      "====================================\n",
      "\n",
      "üîπ F1-Score (Weighted): 0.9726\n",
      "\n",
      "üîπ Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "          Data Booster       0.99      0.99      0.99       159\n",
      "  Device Upgrade Offer       0.99      0.99      0.99       300\n",
      "     Family Plan Offer       0.00      0.00      0.00        16\n",
      "         General Offer       0.98      1.00      0.99      1214\n",
      "       Retention Offer       1.00      0.99      1.00       152\n",
      "          Roaming Pass       0.75      0.95      0.84        19\n",
      "Streaming Partner Pack       0.93      1.00      0.96        52\n",
      "          Top-up Promo       1.00      0.99      0.99        74\n",
      "          Voice Bundle       0.00      0.00      0.00        14\n",
      "\n",
      "              accuracy                           0.98      2000\n",
      "             macro avg       0.74      0.77      0.75      2000\n",
      "          weighted avg       0.97      0.98      0.97      2000\n",
      "\n",
      "\n",
      "üîπ Confusion Matrix:\n",
      "[[ 158    1    0    0    0    0    0    0    0]\n",
      " [   1  297    0    0    0    2    0    0    0]\n",
      " [   0    0    0   16    0    0    0    0    0]\n",
      " [   0    0    0 1210    0    2    2    0    0]\n",
      " [   0    0    1    0  151    0    0    0    0]\n",
      " [   0    0    0    1    0   18    0    0    0]\n",
      " [   0    0    0    0    0    0   52    0    0]\n",
      " [   0    0    0    0    0    1    0   73    0]\n",
      " [   0    1    0   10    0    1    2    0    0]]\n",
      "\n",
      "üîπ ROC-AUC (ovr): 0.9702\n",
      "\n",
      "üìÅ Model berhasil disimpan: catboost_telco_model.cbm\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#   MODEL CATBOOST KHUSUS TELCO | TARGET OFFER PREDICTION\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# LOAD DATASET\n",
    "# =========================================\n",
    "df = pd.read_csv(\"data/raw/data_capstone.csv\")  # sesuai memory Anda\n",
    "\n",
    "# =========================================\n",
    "# PILIH FITUR\n",
    "# =========================================\n",
    "selected_features = [\n",
    "    'plan_type',\n",
    "    'device_brand',\n",
    "    'avg_data_usage_gb',\n",
    "    'pct_video_usage',\n",
    "    'monthly_spend',\n",
    "    'topup_freq',\n",
    "    'travel_score',\n",
    "    'complaint_count'\n",
    "]\n",
    "\n",
    "target = \"target_offer\"\n",
    "\n",
    "X = df[selected_features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# =========================================\n",
    "# ENCODE TARGET LABEL\n",
    "# =========================================\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# =========================================\n",
    "# TRAIN TEST SPLIT\n",
    "# =========================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# CATBOOST NEEDS CATEGORICAL INDEX\n",
    "# =========================================\n",
    "cat_features = [0, 1]  # plan_type, device_brand (index in selected_features)\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "test_pool = Pool(X_test, y_test, cat_features=cat_features)\n",
    "\n",
    "# =========================================\n",
    "# TRAIN CATBOOST MODEL\n",
    "# =========================================\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1200,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1\",\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(train_pool)\n",
    "\n",
    "# =========================================\n",
    "# PREDIKSI\n",
    "# =========================================\n",
    "y_pred = model.predict(test_pool)\n",
    "y_pred = y_pred.flatten().astype(int)\n",
    "\n",
    "y_pred_proba = model.predict_proba(test_pool)\n",
    "\n",
    "# =========================================\n",
    "# EVALUATION METRICS\n",
    "# =========================================\n",
    "\n",
    "print(\"\\n====================================\")\n",
    "print(\"‚ö° CATBOOST EVALUATION METRICS\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "# 1. F1 SCORE\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"üîπ F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# 2. CLASSIFICATION REPORT\n",
    "print(\"\\nüîπ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# 3. CONFUSION MATRIX\n",
    "print(\"\\nüîπ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 4. ROC-AUC MULTICLASS\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(f\"\\nüîπ ROC-AUC (ovr): {auc:.4f}\")\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è ROC-AUC tidak bisa dihitung karena distribusi kelas tertentu tidak valid.\")\n",
    "\n",
    "# =========================================\n",
    "# SIMPAN MODEL\n",
    "# =========================================\n",
    "model.save_model(\"catboost_telco_model.cbm\")\n",
    "print(\"\\nüìÅ Model berhasil disimpan: catboost_telco_model.cbm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad8129",
   "metadata": {},
   "source": [
    "# CatBoost menggunakan data preposesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b0589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_data_usage_gb</th>\n",
       "      <th>pct_video_usage</th>\n",
       "      <th>avg_call_duration</th>\n",
       "      <th>sms_freq</th>\n",
       "      <th>monthly_spend</th>\n",
       "      <th>topup_freq</th>\n",
       "      <th>travel_score</th>\n",
       "      <th>complaint_count</th>\n",
       "      <th>plan_type_Prepaid</th>\n",
       "      <th>device_brand_Huawei</th>\n",
       "      <th>device_brand_Oppo</th>\n",
       "      <th>device_brand_Realme</th>\n",
       "      <th>device_brand_Samsung</th>\n",
       "      <th>device_brand_Vivo</th>\n",
       "      <th>device_brand_Xiaomi</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.061621</td>\n",
       "      <td>2.046720</td>\n",
       "      <td>-0.486489</td>\n",
       "      <td>-0.521547</td>\n",
       "      <td>-0.860550</td>\n",
       "      <td>0.593283</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>0.796856</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>2.376994</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.159227</td>\n",
       "      <td>-1.507241</td>\n",
       "      <td>-0.147440</td>\n",
       "      <td>-1.552817</td>\n",
       "      <td>-1.011679</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>-1.055531</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>-1.254932</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>2.483401</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.647391</td>\n",
       "      <td>-0.454985</td>\n",
       "      <td>-1.209649</td>\n",
       "      <td>-0.521547</td>\n",
       "      <td>-0.450343</td>\n",
       "      <td>2.347810</td>\n",
       "      <td>0.762691</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>-1.254932</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>2.412867</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152220</td>\n",
       "      <td>0.087267</td>\n",
       "      <td>-0.705368</td>\n",
       "      <td>-1.810634</td>\n",
       "      <td>-0.925319</td>\n",
       "      <td>0.593283</td>\n",
       "      <td>0.125934</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>0.796856</td>\n",
       "      <td>-0.409856</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.964016</td>\n",
       "      <td>-0.772672</td>\n",
       "      <td>0.163712</td>\n",
       "      <td>1.540993</td>\n",
       "      <td>-0.817370</td>\n",
       "      <td>1.178125</td>\n",
       "      <td>1.298936</td>\n",
       "      <td>-0.699682</td>\n",
       "      <td>0.796856</td>\n",
       "      <td>2.439882</td>\n",
       "      <td>-0.399751</td>\n",
       "      <td>-0.420699</td>\n",
       "      <td>-0.408663</td>\n",
       "      <td>-0.402674</td>\n",
       "      <td>-0.414445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_data_usage_gb  pct_video_usage  avg_call_duration  sms_freq  \\\n",
       "0          -1.061621         2.046720          -0.486489 -0.521547   \n",
       "1          -1.159227        -1.507241          -0.147440 -1.552817   \n",
       "2          -0.647391        -0.454985          -1.209649 -0.521547   \n",
       "3          -0.152220         0.087267          -0.705368 -1.810634   \n",
       "4          -0.964016        -0.772672           0.163712  1.540993   \n",
       "\n",
       "   monthly_spend  topup_freq  travel_score  complaint_count  \\\n",
       "0      -0.860550    0.593283      0.013842        -0.699682   \n",
       "1      -1.011679    0.008441     -1.055531        -0.699682   \n",
       "2      -0.450343    2.347810      0.762691        -0.699682   \n",
       "3      -0.925319    0.593283      0.125934        -0.699682   \n",
       "4      -0.817370    1.178125      1.298936        -0.699682   \n",
       "\n",
       "   plan_type_Prepaid  device_brand_Huawei  device_brand_Oppo  \\\n",
       "0           0.796856            -0.409856          -0.399751   \n",
       "1          -1.254932            -0.409856          -0.399751   \n",
       "2          -1.254932            -0.409856          -0.399751   \n",
       "3           0.796856            -0.409856          -0.399751   \n",
       "4           0.796856             2.439882          -0.399751   \n",
       "\n",
       "   device_brand_Realme  device_brand_Samsung  device_brand_Vivo  \\\n",
       "0             2.376994             -0.408663          -0.402674   \n",
       "1            -0.420699             -0.408663           2.483401   \n",
       "2            -0.420699             -0.408663          -0.402674   \n",
       "3            -0.420699             -0.408663          -0.402674   \n",
       "4            -0.420699             -0.408663          -0.402674   \n",
       "\n",
       "   device_brand_Xiaomi  target  \n",
       "0            -0.414445       3  \n",
       "1            -0.414445       3  \n",
       "2             2.412867       3  \n",
       "3            -0.414445       3  \n",
       "4            -0.414445       3  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/processed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a349f8",
   "metadata": {},
   "source": [
    "- Hanya menggunakan train‚Äìtest split, tanpa validation.\n",
    "- Tidak ada early stopping.\n",
    "- Regularisasi minimal.\n",
    "- Tidak memantau performa selama training (tidak ada eval_set).\n",
    "- Jumlah iterasi lebih besar (600).\n",
    "- Fokus pada efisiensi RAM, tetapi lebih rawan overfitting\n",
    "\n",
    "##### OVER FITTING PARAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5851b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "‚ö° CATBOOST EVALUATION METRICS (SAFE MODE)\n",
      "====================================\n",
      "\n",
      "üîπ F1-Score (Weighted): 0.9939\n",
      "\n",
      "üîπ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       157\n",
      "           1       0.99      1.00      0.99       293\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00      1185\n",
      "           4       0.99      1.00      0.99       148\n",
      "           5       0.89      0.94      0.92        18\n",
      "           6       1.00      1.00      1.00        51\n",
      "           7       1.00      1.00      1.00        73\n",
      "           8       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.99      1954\n",
      "   macro avg       0.98      0.98      0.98      1954\n",
      "weighted avg       0.99      0.99      0.99      1954\n",
      "\n",
      "\n",
      "üîπ Confusion Matrix:\n",
      "[[ 151    3    0    1    1    1    0    0    0]\n",
      " [   1  292    0    0    0    0    0    0    0]\n",
      " [   0    0   16    0    0    0    0    0    0]\n",
      " [   1    0    0 1182    0    1    0    0    1]\n",
      " [   0    0    0    0  148    0    0    0    0]\n",
      " [   0    0    0    1    0   17    0    0    0]\n",
      " [   0    0    0    0    0    0   51    0    0]\n",
      " [   0    0    0    0    0    0    0   73    0]\n",
      " [   0    0    0    0    1    0    0    0   12]]\n",
      "\n",
      "üîπ ROC-AUC (ovr): 1.0000\n",
      "\n",
      "üìÅ Model berhasil disimpan ‚Üí catboost_telco_model.cbm\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#   MODEL CATBOOST TELCO | NUMPY VERSION (SAFE MODE)\n",
    "# ==========================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# LOAD DATA SPLIT\n",
    "\n",
    "X_train = np.load(\"data/processed/x_train.npy\")\n",
    "y_train = np.load(\"data/processed/y_train.npy\")\n",
    "X_test  = np.load(\"data/processed/x_test.npy\")\n",
    "y_test  = np.load(\"data/processed/y_test.npy\")\n",
    "\n",
    "\n",
    "# CATBOOST SAFE CONFIG (ANTI BAD-ALLOCATION)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=600,          # dari 1500 ‚Üí 600 (lebih ringan, masih akurat)\n",
    "    learning_rate=0.05,\n",
    "    depth=6,                 # dari 10 ‚Üí 6 (mengurangi RAM 50%)\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1\",\n",
    "    random_seed=42,\n",
    "    task_type=\"CPU\",\n",
    "    grow_policy=\"Depthwise\", # lebih hemat memori\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# PREDIKSI\n",
    "y_pred = model.predict(X_test).astype(int).flatten()\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# EVALUATION METRICS\n",
    "\n",
    "print(\"\\n====================================\")\n",
    "print(\"‚ö° CATBOOST EVALUATION METRICS (SAFE MODE)\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"üîπ F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "print(\"\\nüîπ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nüîπ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(f\"\\nüîπ ROC-AUC (ovr): {auc:.4f}\")\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è ROC-AUC tidak bisa dihitung karena ada kelas kosong.\")\n",
    "\n",
    "# SAVE MODEL\n",
    "\n",
    "model.save_model(\"catboost_telco_model.cbm\")\n",
    "print(\"\\nüìÅ Model berhasil disimpan ‚Üí catboost_telco_model.cbm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84a15b",
   "metadata": {},
   "source": [
    "https://chatgpt.com/s/t_691ea8aa0e7c8191b7eb688db360f0fa\n",
    "OVERFITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e6a37",
   "metadata": {},
   "source": [
    "- Menggunakan train‚Äìvalidation‚Äìtest, sehingga model dipantau selama training.\n",
    "- Memakai early stopping untuk menghentikan training jika performa tidak meningkat.\n",
    "- Regularisasi lebih lengkap:\n",
    "subsample,colsample_bylevel,l2_leaf_reg,random_strength\n",
    "- Training menggunakan eval_set, sehingga performa dievaluasi setiap iterasi.\n",
    "- Iterasi lebih sedikit (400) karena sudah dibantu kontrol overfitting.\n",
    "- Lebih aman, stabil, dan minim overfitting.\n",
    "\n",
    "##### KODE INI MASIH OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3cfe589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CATBOOST FINAL METRICS ===\n",
      "F1-Weighted: 0.9899\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       157\n",
      "           1       0.99      0.99      0.99       293\n",
      "           2       0.94      1.00      0.97        16\n",
      "           3       1.00      0.99      1.00      1185\n",
      "           4       0.97      1.00      0.99       148\n",
      "           5       0.82      1.00      0.90        18\n",
      "           6       0.96      1.00      0.98        51\n",
      "           7       1.00      1.00      1.00        73\n",
      "           8       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.99      1954\n",
      "   macro avg       0.95      0.99      0.97      1954\n",
      "weighted avg       0.99      0.99      0.99      1954\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 150    3    0    0    1    3    0    0    0]\n",
      " [   2  290    1    0    0    0    0    0    0]\n",
      " [   0    0   16    0    0    0    0    0    0]\n",
      " [   2    0    0 1175    3    1    2    0    2]\n",
      " [   0    0    0    0  148    0    0    0    0]\n",
      " [   0    0    0    0    0   18    0    0    0]\n",
      " [   0    0    0    0    0    0   51    0    0]\n",
      " [   0    0    0    0    0    0    0   73    0]\n",
      " [   0    0    0    0    0    0    0    0   13]]\n",
      "\n",
      "ROC-AUC (ovr): 0.9999\n",
      "\n",
      "Model saved ‚Üí catboost_telco_model.cbm\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD DATA\n",
    "# ==========================================================\n",
    "X_train = np.load(\"data/processed/x_train.npy\")\n",
    "y_train = np.load(\"data/processed/y_train.npy\")\n",
    "X_test  = np.load(\"data/processed/x_test.npy\")\n",
    "y_test  = np.load(\"data/processed/y_test.npy\")\n",
    "\n",
    "# Validation split\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# CATBOOST ‚Äî CPU SAFE & ANTI OVERFITTING\n",
    "# ==========================================================\n",
    "model = CatBoostClassifier(\n",
    "    iterations=400,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1\",\n",
    "    random_seed=42,\n",
    "    task_type=\"CPU\",\n",
    "    grow_policy=\"Depthwise\",\n",
    "\n",
    "    # === FIX: ONLY CPU-SAFE OPTION ===\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    subsample=0.8,\n",
    "\n",
    "    # === Regularization ===\n",
    "    l2_leaf_reg=5,\n",
    "    random_strength=1.2,\n",
    "    colsample_bylevel=0.8,\n",
    "\n",
    "    early_stopping_rounds=40,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# TRAIN\n",
    "model.fit(\n",
    "    X_train2, y_train2,\n",
    "    eval_set=(X_val, y_val),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# PREDIKSI\n",
    "# ==========================================================\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# ==========================================================\n",
    "# METRIK\n",
    "# ==========================================================\n",
    "print(\"\\n=== CATBOOST FINAL METRICS ===\")\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-Weighted: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(f\"\\nROC-AUC (ovr): {auc:.4f}\")\n",
    "except:\n",
    "    print(\"\\nROC-AUC tidak dapat dihitung.\")\n",
    "\n",
    "# SAVE MODEL\n",
    "model.save_model(\"catboost_telco_model.cbm\")\n",
    "print(\"\\nModel saved ‚Üí catboost_telco_model.cbm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e3c699",
   "metadata": {},
   "source": [
    "feat:add initial CatBoost model (baseline, still overfitting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
